{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10644144,
          "sourceType": "datasetVersion",
          "datasetId": 6590681
        }
      ],
      "dockerImageVersionId": 30840,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrAsAnNaRePo/chat-ft/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:22:10.862755Z",
          "iopub.execute_input": "2025-02-02T17:22:10.862986Z",
          "iopub.status.idle": "2025-02-02T17:22:13.876730Z",
          "shell.execute_reply.started": "2025-02-02T17:22:10.862964Z",
          "shell.execute_reply": "2025-02-02T17:22:13.875865Z"
        },
        "id": "FGX1TnIjeXjK",
        "outputId": "063cba43-f3eb-4e28-9eac-46accea9f248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.6.0+cu124'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:22:41.303459Z",
          "iopub.execute_input": "2025-02-02T17:22:41.303805Z",
          "iopub.status.idle": "2025-02-02T17:22:44.762102Z",
          "shell.execute_reply.started": "2025-02-02T17:22:41.303781Z",
          "shell.execute_reply": "2025-02-02T17:22:44.761268Z"
        },
        "id": "hkI9McWOeXjL",
        "outputId": "75df483c-916c-4f50-d4d0-c2b2aef29dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Name: torch\nVersion: 2.5.1+cu121\nSummary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\nHome-page: https://pytorch.org/\nAuthor: PyTorch Team\nAuthor-email: packages@pytorch.org\nLicense: BSD-3-Clause\nLocation: /usr/local/lib/python3.10/dist-packages\nRequires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\nRequired-by: accelerate, easyocr, fastai, kornia, peft, pytorch-ignite, pytorch-lightning, sentence-transformers, stable-baselines3, timm, torchaudio, torchmetrics, torchvision\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install unsloth**\n",
        "- open [unsolth repo](https://github.com/unslothai/unsloth?tab=readme-ov-file) to check what version to is installed.\n",
        "- for my setup i have `torch 2.5.1` and `cuda 12.1`, look for the specific version of unsolth package."
      ],
      "metadata": {
        "id": "-Gjpbmz_eXjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install \"unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:22:44.763242Z",
          "iopub.execute_input": "2025-02-02T17:22:44.763490Z",
          "iopub.status.idle": "2025-02-02T17:25:44.300238Z",
          "shell.execute_reply.started": "2025-02-02T17:22:44.763468Z",
          "shell.execute_reply": "2025-02-02T17:25:44.299344Z"
        },
        "id": "B4-9RrSieXjN",
        "outputId": "ff440725-1d79-4eb2-fb6c-44bd2acdc88a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.0-py3-none-any.whl.metadata (3.7 kB)\nDownloading pip-25.0-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.0\nNote: you may need to restart the kernel to use updated packages.\nCollecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-4di9hok3/unsloth_ddabc9319cf94b32ba93e6442c18912d\n  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-4di9hok3/unsloth_ddabc9319cf94b32ba93e6442c18912d\n  Resolved https://github.com/unslothai/unsloth.git to commit 038e6d4c8d40207a87297ab3aaf787c19b1006d1\n  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting bitsandbytes>=0.43.3 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: torch~=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\nCollecting xformers@ https://download.pytorch.org/whl/cu121/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading https://download.pytorch.org/whl/cu121/xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.1.4 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading unsloth_zoo-2025.1.5-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (24.2)\nCollecting tyro (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading tyro-0.9.13-py3-none-any.whl.metadata (9.4 kB)\nCollecting transformers!=4.47.0,>=4.46.1 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\nRequirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.2.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.45.1)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.2.1)\nCollecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.27.0)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.9)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\nRequirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.9.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.11.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.47.0,>=4.46.1->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.21.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (13.9.4)\nCollecting triton<3.2.0 (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from unsloth_zoo>=2025.1.4->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (11.0.0)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.4.1)\nCollecting torch~=2.0 (from bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.21.5 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.4.127 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.18.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.12.14)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.0->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes>=0.43.3->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[cu121-torch250]@ git+https://github.com/unslothai/unsloth.git) (1.17.0)\nDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.48.2-py3-none-any.whl (9.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m136.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.14.0-py3-none-any.whl (313 kB)\nDownloading unsloth_zoo-2025.1.5-py3-none-any.whl (80 kB)\nDownloading tyro-0.9.13-py3-none-any.whl (115 kB)\nDownloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m146.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m111.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\nDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\nDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nBuilding wheels for collected packages: unsloth\n  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for unsloth: filename=unsloth-2025.1.8-py3-none-any.whl size=174982 sha256=3b0031265939a47678435d9956a5f6d2d4cc6348f2b79379d63abc74dabf07df\n  Stored in directory: /tmp/pip-ephem-wheel-cache-a5j6f6s7/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\nSuccessfully built unsloth\nInstalling collected packages: unsloth, triton, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, transformers, trl, xformers, unsloth_zoo, bitsandbytes\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.23.4\n    Uninstalling nvidia-nccl-cu12-2.23.4:\n      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.7.77\n    Uninstalling nvidia-curand-cu12-10.3.7.77:\n      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.6.0.74\n    Uninstalling nvidia-cudnn-cu12-9.6.0.74:\n      Successfully uninstalled nvidia-cudnn-cu12-9.6.0.74\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n  Attempting uninstall: torch\n    Found existing installation: torch 2.5.1+cu121\n    Uninstalling torch-2.5.1+cu121:\n      Successfully uninstalled torch-2.5.1+cu121\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.10.0 requires pylibraft-cu12==24.10.*, but you have pylibraft-cu12 24.12.0 which is incompatible.\npylibcugraph-cu12 24.10.0 requires rmm-cu12==24.10.*, but you have rmm-cu12 24.12.1 which is incompatible.\ntorchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\ntorchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 2.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.1 cut_cross_entropy-25.1.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 shtab-1.7.1 torch-2.5.0 transformers-4.48.2 triton-3.1.0 trl-0.14.0 tyro-0.9.13 unsloth-2025.1.8 unsloth_zoo-2025.1.5 xformers-0.0.28.post2\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **NOTE**:\n",
        "> please make sure to restart the session inoder to use the latest dependicies we've instaled."
      ],
      "metadata": {
        "id": "D0ncnXbFeXjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prepare the code**\n",
        "- clone the repo by using `git clone https://github.com/PrAsAnNaRePo/chat-ft.git`"
      ],
      "metadata": {
        "id": "mIAIUBtceXjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrAsAnNaRePo/chat-ft.git"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:26:29.109853Z",
          "iopub.execute_input": "2025-02-02T17:26:29.110159Z",
          "iopub.status.idle": "2025-02-02T17:26:29.509231Z",
          "shell.execute_reply.started": "2025-02-02T17:26:29.110136Z",
          "shell.execute_reply": "2025-02-02T17:26:29.508223Z"
        },
        "id": "sKTUEnK9eXjO",
        "outputId": "3f262fc0-7810-4a46-b27d-1b2bb07ee7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Cloning into 'chat-ft'...\nremote: Enumerating objects: 23, done.\u001b[K\nremote: Counting objects: 100% (23/23), done.\u001b[K\nremote: Compressing objects: 100% (16/16), done.\u001b[K\nremote: Total 23 (delta 10), reused 19 (delta 6), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (23/23), 11.00 KiB | 563.00 KiB/s, done.\nResolving deltas: 100% (10/10), done.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**import dataset**\n",
        "- export a chat of your interest in th whatsapp, this will gives you the `.txt` file.\n",
        "- use the file as the dataset to train the model."
      ],
      "metadata": {
        "id": "n0823jgReXjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set the wandb for logging\n",
        "import os\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = \"your_api_key_here\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:26:31.587347Z",
          "iopub.execute_input": "2025-02-02T17:26:31.587659Z",
          "iopub.status.idle": "2025-02-02T17:26:31.591487Z",
          "shell.execute_reply.started": "2025-02-02T17:26:31.587634Z",
          "shell.execute_reply": "2025-02-02T17:26:31.590745Z"
        },
        "id": "s14333AAeXjO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# login to HF to push models to the repo\n",
        "!pip install -U \"huggingface_hub[cli]\"\n",
        "!huggingface-cli login --token \"your_api_key_here\" # get you access token from https://huggingface.co/settings/tokens"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:26:32.644317Z",
          "iopub.execute_input": "2025-02-02T17:26:32.644650Z",
          "iopub.status.idle": "2025-02-02T17:26:38.322867Z",
          "shell.execute_reply.started": "2025-02-02T17:26:32.644590Z",
          "shell.execute_reply": "2025-02-02T17:26:38.321816Z"
        },
        "id": "0NH_LMa_eXjQ",
        "outputId": "dfbaadfd-3fe9-4498-c634-a107765601a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.10/dist-packages (0.27.0)\nCollecting huggingface_hub[cli]\n  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2024.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2.32.3)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.12.2)\nCollecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\nCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\nRequirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.48)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2024.12.14)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)\nDownloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\nDownloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\nDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\nInstalling collected packages: pfzy, InquirerPy, huggingface_hub\n  Attempting uninstall: huggingface_hub\n    Found existing installation: huggingface-hub 0.27.0\n    Uninstalling huggingface-hub-0.27.0:\n      Successfully uninstalled huggingface-hub-0.27.0\nSuccessfully installed InquirerPy-0.3.4 huggingface_hub-0.28.1 pfzy-0.3.4\nThe token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nThe token `chat-ft-tutorial` has been saved to /root/.cache/huggingface/stored_tokens\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful.\nThe current active token is: `chat-ft-tutorial`\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!cd chat-ft && python train.py \\\n",
        "  --chat_file_path /kaggle/input/chat-file/raw_chat.txt \\\n",
        "  --target_role \"<your target chat name>\" \\\n",
        "  --hr_gap 3 \\\n",
        "  --low_gpu_memory True \\\n",
        "  --output_path ./unsloth_qwen-chat-ft \\\n",
        "  --num_epochs 4 \\\n",
        "  --per_device_train_batch_size 8 \\\n",
        "  --gradient_accumulation_steps 4 \\\n",
        "  --wandb_logger True"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T17:28:02.731915Z",
          "iopub.execute_input": "2025-02-02T17:28:02.732254Z",
          "iopub.status.idle": "2025-02-02T18:37:11.164367Z",
          "shell.execute_reply.started": "2025-02-02T17:28:02.732226Z",
          "shell.execute_reply": "2025-02-02T18:37:11.163323Z"
        },
        "id": "xau0fIWIeXjQ",
        "outputId": "12c5d9df-a80d-43d3-d0bf-bb6031725f1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "2025-02-02 17:28:07.330213: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-02-02 17:28:07.352263: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-02-02 17:28:07.358759: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\nFigure(1200x600)\nFigure(1200x600)\nFigure(1600x600)\nLenght of dataset:  509\n==((====))==  Unsloth 2025.1.8: Fast Qwen2 patching. Transformers: 4.48.2.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.1.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nmodel.safetensors: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.14G/1.14G [00:25<00:00, 42.0MB/s]\ngeneration_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 265/265 [00:00<00:00, 1.88MB/s]\ntokenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.51k/7.51k [00:00<00:00, 37.6MB/s]\nvocab.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.78M/2.78M [00:00<00:00, 26.7MB/s]\nmerges.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.67M/1.67M [00:00<00:00, 9.45MB/s]\nadded_tokens.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 632/632 [00:00<00:00, 4.63MB/s]\nspecial_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 613/613 [00:00<00:00, 5.00MB/s]\ntokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.03M/7.03M [00:00<00:00, 26.1MB/s]\nUnsloth 2025.1.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\nNumber of GPUs:  1\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpras\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.1\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/chat-ft/wandb/run-20250202_172855-2q9h0pob\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mqwen2.5-2b-chat-ft\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/pras/chat-ft\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/pras/chat-ft/runs/2q9h0pob\u001b[0m\n==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n   \\\\   /|    Num examples = 509 | Num Epochs = 4\nO^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n\\        /    Total batch size = 32 | Total steps = 64\n \"-____-\"     Number of trainable parameters = 18,464,768\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n{'loss': 3.8371, 'grad_norm': 1.9257696866989136, 'learning_rate': 0.0002, 'epoch': 0.06}\n{'loss': 3.5238, 'grad_norm': 0.8229120373725891, 'learning_rate': 0.0002, 'epoch': 0.12}\n{'loss': 3.5227, 'grad_norm': 0.37260493636131287, 'learning_rate': 0.0002, 'epoch': 0.19}\n{'loss': 3.3733, 'grad_norm': 0.4256563186645508, 'learning_rate': 0.0002, 'epoch': 0.25}\n{'loss': 3.4992, 'grad_norm': 0.41178062558174133, 'learning_rate': 0.0002, 'epoch': 0.31}\n{'loss': 3.2499, 'grad_norm': 0.2979547679424286, 'learning_rate': 0.0002, 'epoch': 0.38}\n{'loss': 3.3974, 'grad_norm': 0.37043043971061707, 'learning_rate': 0.0002, 'epoch': 0.44}\n{'loss': 3.3794, 'grad_norm': 0.38418686389923096, 'learning_rate': 0.0002, 'epoch': 0.5}\n{'loss': 3.0327, 'grad_norm': 0.32622528076171875, 'learning_rate': 0.0002, 'epoch': 0.56}\n{'loss': 3.3507, 'grad_norm': 0.6119401454925537, 'learning_rate': 0.0002, 'epoch': 0.62}\n{'loss': 2.554, 'grad_norm': 0.3055408000946045, 'learning_rate': 0.0002, 'epoch': 0.69}\n{'loss': 3.0922, 'grad_norm': 0.37168529629707336, 'learning_rate': 0.0002, 'epoch': 0.75}\n{'loss': 3.2684, 'grad_norm': 0.4906444847583771, 'learning_rate': 0.0002, 'epoch': 0.81}\n{'loss': 3.0514, 'grad_norm': 0.45395612716674805, 'learning_rate': 0.0002, 'epoch': 0.88}\n{'loss': 3.1393, 'grad_norm': 0.36222898960113525, 'learning_rate': 0.0002, 'epoch': 0.94}\n{'loss': 3.0451, 'grad_norm': 0.5435910224914551, 'learning_rate': 0.0002, 'epoch': 1.0}\n{'loss': 2.9683, 'grad_norm': 0.5276546478271484, 'learning_rate': 0.0002, 'epoch': 1.06}\n{'loss': 2.9782, 'grad_norm': 0.2545865476131439, 'learning_rate': 0.0002, 'epoch': 1.12}\n{'loss': 2.8792, 'grad_norm': 0.5053395628929138, 'learning_rate': 0.0002, 'epoch': 1.19}\n{'loss': 2.4196, 'grad_norm': 0.24581684172153473, 'learning_rate': 0.0002, 'epoch': 1.25}\n{'loss': 2.8915, 'grad_norm': 0.40166449546813965, 'learning_rate': 0.0002, 'epoch': 1.31}\n{'loss': 2.8188, 'grad_norm': 0.33439385890960693, 'learning_rate': 0.0002, 'epoch': 1.38}\n{'loss': 2.713, 'grad_norm': 0.4154990017414093, 'learning_rate': 0.0002, 'epoch': 1.44}\n{'loss': 2.867, 'grad_norm': 0.3674134612083435, 'learning_rate': 0.0002, 'epoch': 1.5}\n{'loss': 2.8806, 'grad_norm': 0.36409446597099304, 'learning_rate': 0.0002, 'epoch': 1.56}\n{'loss': 2.9321, 'grad_norm': 0.609940767288208, 'learning_rate': 0.0002, 'epoch': 1.62}\n{'loss': 2.7193, 'grad_norm': 0.298701673746109, 'learning_rate': 0.0002, 'epoch': 1.69}\n{'loss': 2.752, 'grad_norm': 0.3229080140590668, 'learning_rate': 0.0002, 'epoch': 1.75}\n{'loss': 2.8601, 'grad_norm': 0.2683970332145691, 'learning_rate': 0.0002, 'epoch': 1.81}\n{'loss': 2.7233, 'grad_norm': 0.2837173044681549, 'learning_rate': 0.0002, 'epoch': 1.88}\n{'loss': 2.6862, 'grad_norm': 0.3767976462841034, 'learning_rate': 0.0002, 'epoch': 1.94}\n{'loss': 2.681, 'grad_norm': 0.3270924389362335, 'learning_rate': 0.0002, 'epoch': 2.0}\n{'loss': 2.7645, 'grad_norm': 0.25270935893058777, 'learning_rate': 0.0002, 'epoch': 2.06}\n{'loss': 2.69, 'grad_norm': 0.2826073467731476, 'learning_rate': 0.0002, 'epoch': 2.12}\n{'loss': 2.643, 'grad_norm': 0.3120931386947632, 'learning_rate': 0.0002, 'epoch': 2.19}\n{'loss': 2.6401, 'grad_norm': 0.2900530993938446, 'learning_rate': 0.0002, 'epoch': 2.25}\n{'loss': 2.7731, 'grad_norm': 0.39819207787513733, 'learning_rate': 0.0002, 'epoch': 2.31}\n{'loss': 2.6492, 'grad_norm': 0.2795444130897522, 'learning_rate': 0.0002, 'epoch': 2.38}\n{'loss': 2.6028, 'grad_norm': 0.3917770981788635, 'learning_rate': 0.0002, 'epoch': 2.44}\n{'loss': 2.531, 'grad_norm': 0.3202158808708191, 'learning_rate': 0.0002, 'epoch': 2.5}\n{'loss': 2.1076, 'grad_norm': 0.1679929494857788, 'learning_rate': 0.0002, 'epoch': 2.56}\n{'loss': 2.6124, 'grad_norm': 0.48220333456993103, 'learning_rate': 0.0002, 'epoch': 2.62}\n{'loss': 2.621, 'grad_norm': 0.42314234375953674, 'learning_rate': 0.0002, 'epoch': 2.69}\n{'loss': 2.5902, 'grad_norm': 0.32510247826576233, 'learning_rate': 0.0002, 'epoch': 2.75}\n{'loss': 2.5655, 'grad_norm': 0.32797881960868835, 'learning_rate': 0.0002, 'epoch': 2.81}\n{'loss': 2.5085, 'grad_norm': 0.30852434039115906, 'learning_rate': 0.0002, 'epoch': 2.88}\n{'loss': 2.5812, 'grad_norm': 0.25826239585876465, 'learning_rate': 0.0002, 'epoch': 2.94}\n{'loss': 2.4224, 'grad_norm': 0.4730370342731476, 'learning_rate': 0.0002, 'epoch': 3.0}\n{'loss': 2.7213, 'grad_norm': 0.41837072372436523, 'learning_rate': 0.0002, 'epoch': 3.06}\n{'loss': 2.4814, 'grad_norm': 0.3997613191604614, 'learning_rate': 0.0002, 'epoch': 3.12}\n{'loss': 2.502, 'grad_norm': 0.3875885009765625, 'learning_rate': 0.0002, 'epoch': 3.19}\n{'loss': 2.4914, 'grad_norm': 0.3712103068828583, 'learning_rate': 0.0002, 'epoch': 3.25}\n{'loss': 1.9441, 'grad_norm': 0.2196616232395172, 'learning_rate': 0.0002, 'epoch': 3.31}\n{'loss': 2.4588, 'grad_norm': 0.4160137176513672, 'learning_rate': 0.0002, 'epoch': 3.38}\n{'loss': 2.4907, 'grad_norm': 0.44886064529418945, 'learning_rate': 0.0002, 'epoch': 3.44}\n{'loss': 2.4658, 'grad_norm': 0.4234350323677063, 'learning_rate': 0.0002, 'epoch': 3.5}\n{'loss': 2.4679, 'grad_norm': 1.0926697254180908, 'learning_rate': 0.0002, 'epoch': 3.56}\n{'loss': 2.5134, 'grad_norm': 0.895082950592041, 'learning_rate': 0.0002, 'epoch': 3.62}\n{'loss': 2.4063, 'grad_norm': 0.44745466113090515, 'learning_rate': 0.0002, 'epoch': 3.69}\n{'loss': 2.4898, 'grad_norm': 0.6382306814193726, 'learning_rate': 0.0002, 'epoch': 3.75}\n{'loss': 2.4044, 'grad_norm': 0.32536518573760986, 'learning_rate': 0.0002, 'epoch': 3.81}\n{'loss': 2.4032, 'grad_norm': 0.5308919548988342, 'learning_rate': 0.0002, 'epoch': 3.88}\n{'loss': 2.3739, 'grad_norm': 0.4503041207790375, 'learning_rate': 0.0002, 'epoch': 3.94}\n{'loss': 2.3955, 'grad_norm': 0.39957326650619507, 'learning_rate': 0.0002, 'epoch': 4.0}\n{'train_runtime': 4074.5947, 'train_samples_per_second': 0.5, 'train_steps_per_second': 0.016, 'train_loss': 2.7718643322587013, 'epoch': 4.0}\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [1:07:54<00:00, 63.67s/it]\n\u001b[1;34mwandb\u001b[0m: ðŸš€ View run \u001b[33mqwen2.5-2b-chat-ft\u001b[0m at: \u001b[34mhttps://wandb.ai/pras/chat-ft/runs/2q9h0pob\u001b[0m\n\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250202_172855-2q9h0pob/logs\u001b[0m\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "\n",
        "base_model = 'Qwen/Qwen2.5-1.5B-Instruct'\n",
        "adapter_model = '/kaggle/working/chat-ft/unsloth_qwen-chat-ft/checkpoint-64'\n",
        "prompt = \"what is your name\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model, device_map='auto')\n",
        "model = PeftModel.from_pretrained(model, adapter_model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T18:59:33.829394Z",
          "iopub.execute_input": "2025-02-02T18:59:33.829794Z",
          "iopub.status.idle": "2025-02-02T18:59:40.002305Z",
          "shell.execute_reply.started": "2025-02-02T18:59:33.829764Z",
          "shell.execute_reply": "2025-02-02T18:59:40.001374Z"
        },
        "id": "gQ_816aPeXjR",
        "outputId": "7f1dc522-3f9c-4fb0-eb72-b013fe087906"
      },
      "outputs": [
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): Qwen2ForCausalLM(\n      (model): Qwen2Model(\n        (embed_tokens): Embedding(151936, 1536)\n        (layers): ModuleList(\n          (0-27): 28 x Qwen2DecoderLayer(\n            (self_attn): Qwen2Attention(\n              (q_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=1536, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (k_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (v_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=256, bias=True)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=256, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (o_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n            )\n            (mlp): Qwen2MLP(\n              (gate_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (up_proj): lora.Linear(\n                (base_layer): Linear(in_features=1536, out_features=8960, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=1536, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=8960, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (down_proj): lora.Linear(\n                (base_layer): Linear(in_features=8960, out_features=1536, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Identity()\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=8960, out_features=16, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=16, out_features=1536, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n                (lora_magnitude_vector): ModuleDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n            (post_attention_layernorm): Qwen2RMSNorm((1536,), eps=1e-06)\n          )\n        )\n        (norm): Qwen2RMSNorm((1536,), eps=1e-06)\n        (rotary_emb): Qwen2RotaryEmbedding()\n      )\n      (lm_head): Linear(in_features=1536, out_features=151936, bias=False)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenized = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\n",
        "            'role': 'system',\n",
        "            'content': 'a conversation between interesting peoples'\n",
        "        },\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': \"hey, what up!\"\n",
        "        }\n",
        "    ],\n",
        "    tokenize=False\n",
        ")\n",
        "\n",
        "tokens = tokenizer(tokenized, return_tensors='pt').to('cuda')\n",
        "\n",
        "res = model.generate(**tokens, max_new_tokens=150)\n",
        "print(tokenizer.decode(res.reshape(-1)))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-02-02T18:57:25.871193Z",
          "iopub.execute_input": "2025-02-02T18:57:25.871557Z",
          "iopub.status.idle": "2025-02-02T18:57:26.532089Z",
          "shell.execute_reply.started": "2025-02-02T18:57:25.871509Z",
          "shell.execute_reply": "2025-02-02T18:57:26.531173Z"
        },
        "id": "HOfaZHNieXjR",
        "outputId": "5960407a-a454-4b32-c76d-2b8e1e24da25"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<|im_start|>system\na conversation between interesting peoples<|im_end|>\n<|im_start|>user\nhey, what up!<|im_end|>\n<|im_start|>assistant\nNothing much\nU?<|im_end|>\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}